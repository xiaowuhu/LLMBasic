
## 3.1 机器翻译问题

机器翻译作为自然语言处理的一个核心领域，一直都是研究者们关注的焦点。其目标是实现计算机自动将一种语言翻译成另一种语言，使用特定的算法和模型，尝试在不同语言之间实现最佳的语义映射。本节中我们将讲述与机器翻译相关的基本概念。

当你在翻译软件中输入“Hello, world!”，并指定将其从英语翻译成法语，你会得到 "Bonjour le monde!”，这就是机器翻译的一个简单示例。源语言是英语，目标语言是法语。有些翻译软件能够自动检测用户输入的源语言的语种，其原理与第 1.6 节中的姓氏数据分类相似。

下面的四个例句是英法对照的例子，左侧的是英语，右侧的是法语，中间用 `\t` 字符分开。

```
# 英语               # 法语
he is ill           il est malade
you re shy          vous etes timide
we re twins         nous sommes jumelles
i am in the house   je suis dans la maison
```

为了简化起见，我们挑选的英语句子都是以下面的词开头的，并且词的数量小于 10 个：

```python
MAX_LENGTH = 10
eng_prefixes_filter = (
    "i am ", "i m ", "he is", "he s ", "she is", "she s ",
    "you are", "you re ", "we are", "we re ", "they are", "they re "
)
```
**问题：现在我们已经有了一万多个简单的英法对照的句子，如何实现双向的机器翻译？**

### 3.1.1 各种机器翻译技术

表 3.1.1 列出各种机器翻译技术的概要信息。

- 基于规则的机器翻译（rule based machine translation，RBMT）模拟人类的翻译习惯，以词典和语法为基本规则进行对译。

- 统计模型机器翻译（statistic machine translation，SMT）利用统计模型从大量双语文本数据中学习如何将源语言翻译为目标语言。与依赖语言学家手工编写规则的 RBMT 不同，SMT 自动从数据中学习翻译规则和模式。

- 最先进的神经网络机器翻译（neural-net machine translation，NMT）使用深度学习技术，以 RNN、LSTM、GRU、词嵌入、注意力机制等为基础，以端到端的方式进行翻译，不需要中间步骤。

表 3.1.1 各种机器翻译技术比较

|简称|RBMT|SMT|NMT|
|-|-|-|-|
|**中文名称**|基于规则的机器翻译|统计模型机器翻译|神经网络机器翻译|
|**技术基础**|基于词典、语法知识|基于海量对译数据统计信息|使用深度学习|
|**优点**|翻译速度快，忠实于原文，适合固定格式文章翻译|翻译质量较高，译文比较自然|翻译质量最高，译文自然流畅|
|**缺点**|词典缺失数据时将无法进行|译文不够自然|训练时间较长|

### 3.1.2 序列到序列问题

前面章节讲到的RNN模型和实例，都属于序列预测问题，或是通过序列中一个时间步的输入值，预测下一个时间步输出值（如二进制减法问题）；或是对所有输入序列得到一个输出作为分类（如名字分类问题）。他们的共同特点是：输出序列与输入序列等长，或输出长度为1。

还有一类序列预测问题，以序列作为输入，输出的也是序列，但是输入和输出序列长度不确定。这类问题被称为**序列到序列**（sequence-to-sequence, seq2seq）预测问题，它有很多应用场景，比如：机器翻译、问答系统、文档摘要生成等。简单的 RNN 结构无法处理这类问题，于是科学家们提出了**编码-解码（encoder-decoder）模型**，图 3.1.1 为该结构的示意图。

<img src="./img/encoder-decoder.png" width=580/>

图 3.1.1 编码-解码模型示意图

在示意图中，输入序列和输出序列分别为中文语句“我弹吉他”和对应的英文语句“I play guitar”，它们的长度不一定相同。编码器将输入序列编码成为固定长度的状态向量，通常称为语义编码向量或**上下文向量**（context vector）。解码器将上下文向量作为原始输入，解码成所需要的输出序列。在具体实现中，编码器、解码器可以有不同选择，可自由组合，常见的选择有 CNN、RNN、GRU、LSTM 等，当然还有更高级的 Transformer 将在本章中后面的部分讲解。

### 3.1.3 评价和评估方法

机器翻译的评价是衡量模型性能的关键部分。准确、流畅和自然的翻译输出是我们的目标，但如何量化这些目标并确定模型的质量呢？以下是一些评估方法，这些方法的名字都是一些英文缩写，没有准确的中文名词。

#### 1. BLEU

双语评估替补（bilingual evaluation understudy，BLEU）分数是机器翻译中最常用的评估方法。它通过比较机器翻译输出和多个参考翻译之间的 n-gram 的重叠率来工作，具体地说是机器翻译输出的 n-gram 是否出现在标签序列中。

$$
\text{BLEU}=\exp(\min(0, 1- \frac{\text{len}_{label}}{\text{len}_{pred}}))\prod_{n=1}^k p_n^{1/2^n}
$$

其中，$\text{len}_{label}$ 表示标签序列中的词元数，$\text{len}_{pred}$ 表示预测序列中的词元数，$k$ 是用于匹配的最长的 n-gram。$p_n$ 表示 n-gram 的精确度，它是两个数的比值： 分子是预测序列与标签序列中匹配的 n-gram 数量， 分母是预测序列中 n-gram 的数量的比率。比如标签序列是 ABCDE，预测序列是 ABBCD，1-gram 时 $p_1=4/5$，2-gram 时 $p_2=3/4$，3-gram 时 $p_3=1/3$。

示例：假设机器的预测输出是 “the cat is on the mat”，而标签是 “the cat is sitting on the mat”，运行【代码：H3_1_BLEU.py】可以得到以下结果：

```
预测: the cat is on the mat
标签: the cat is sitting on the mat
BLEU: 1-gram: 0.846482, 2-gram: 0.800553, 3-gram: 0.734110, 4-gram: 0.000000
```
我们一般使用 2-gram 作为评测标准。

#### 2. METEOR

显式排序翻译评价指标（metric for evaluation of translation with explicit ordering，METEOR）是另一个评估机器翻译的方法，它考虑了同义词匹配、词干匹配以及词序。

示例：如果机器输出是 “the pet is on the rug”，而参考翻译是 “the cat is on the mat”，尽管有些词不完全匹配，但 METEOR 会认为"pet"和"cat"、"rug"和"mat"之间有某种相似性。

#### 3. ROUGE

以回忆为导向的注册评估研究（recall-oriented understudy for gisting evaluation，ROUGE）通常用于评估自动文摘，但也可以用于机器翻译。它考虑了机器翻译输出和参考翻译之间的 n-gram 的召回率。

示例：对于同样的句子 “the cat is on the mat” 和 “the cat is sitting on the mat”，ROUGE-1 召回率为 6/7。

#### 4. TER

翻译编辑率（translation edit rate，TER）衡量了将机器翻译输出转换为参考翻译所需的最少编辑次数（如插入、删除、替换等）。

示例：对于 “the cat sat on the mat” 和 “the cat is sitting on the mat”，TER是 2/7，因为需要添加一个“is”，修改一个“sitting”。

#### 5. 人工评估

尽管自动评估方法提供了快速的反馈，但人工评估仍然是确保翻译质量的金标准。评估者通常会根据准确性、流畅性和是否忠实于源文本来评分。

示例：一个句子可能获得很高的 BLEU 分数，但如果其翻译内容与源内容的意图不符，或者读起来不自然，那么人类评估者可能会给予较低的评分。

总的来说，评估机器翻译的性能是一个多方面的任务，涉及到多种工具和方法。理想情况下，研究者和开发者会结合多种评估方法，以获得对模型性能的全面了解。
