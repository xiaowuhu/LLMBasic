
## 9.1 竞争者的探索

在 GPT 系列模型的带动下，市场上还出现了很多大语言模型，不得不提的是开源阵营中的两位“领军人物”，一个是 Meta 公司的 LLaMA 模型，另外一个是国内的深度求索（DeepSeek）模型。下面对这两个模型做一个简要的介绍。

### 9.1.1 开源与闭源的竞争

OpenAI 一直采用闭源策略，而由 Meta 公司推出的 LLaMA（large language model Meta AI）系列开源模型打破了这一局面，到目前为止，共有三个版本的 LLaMA 发布，如表 9.1.1 所示。

表 9.1.1 LLaMA 系列模型

||LLaMA-1|LLaMA-2|LLaMA-3|
|-|-|-|-|
|发布时间|2023年2月 |2023年7月|2024年4月|
|模型规模|7B,13B,30B,65B|7B,13B,34B,70B|1B,3B,11B,70B,90B,405B|
|训练数据量|1.4 万亿|2 万亿|15 万亿|
|上下文长度|2048|4096|128k|
|分词器|SentencePiece BPE，32k 词汇表|SentencePiece BPE，32k 词汇表|tiktoken BPE，128k 词汇表|
|注意力机制|Multi-Head Attention (MHA)|Grouped Query Attention (GQA)+ kv cache|Grouped Query Attention (GQA) + kv cache|
|训练资源|2048 * A100 80GB|3.3M GPU hours on A100-80GB|16K H100 80GB|
|应用场景|通用语言理解与生成|通用语言理解与生成，推理效率进一步提升|多模态应用（图像、语音）、轻量级部署、边缘设备适配|

LLaMA 在大多数基准测试中都与 OpenAI 的模型具有可比性甚至性能更好，但参数量要小很多，所以迅速成为了开源社区最受欢迎的大模型之一，并产生了 LLaMA 生态圈。众多研究者将其作为基座模型，进行了继续预训练或者微调，衍生出了众多变体模型，极大地推动了大模型领域的研究进展。

### 9.1.2 推理模型的竞争

在 OpenAI 推出了 o1 **推理模型**之后，又成为了市场焦点，当然，它还是闭源的。不同于传统的语言预测模型，它在产生输出之前会先生成一个内部的思维链，逐步推导、分解问题，模拟了人类思考的方式，使得模型能够更深入地理解问题并给出更准确的答案。它能够在数学、编码、科学等多个领域表现出色，解决一些传统模型难以应对的复杂问题。例如，在一项高级数学问题测试中，o1解决了83%的问题，而GPT-4o只解决了13%。

作为竞争者，在 2025 年初，国内推出了 DeepSeek-R1 推理模型，成为了第一个可以和 o1 比肩的开源模型。表 9.1.2 是二者的对比。

表 9.1.2 DeepSeek-R1 与 o1 的比较

|基准测试|DeepSeek-R1|OpenAI-o1-1217|
|-|-|-|
|AIME 2024(Pass@1)|79.8%|79.2%|
|MATH-500(Pass@1)|97.3%|96.4%|
|Codeforces(Percentile)|96.3%|96.6%|
|MMLU(Pass@1)|90.8%|91.8%|
|Swe-Bench(Resolved)|49.2%|48.9%|

可以看到，DeepSeek-R1 与 o1 互有胜负，但是都在毫厘之间。当然， DeepSeek-R1 并不是凭空产生的，它有也一系列的产品线做基础，通过观察其历史发布时间可知它的演进速度非常的快。见表 9.1.3。

表 9.1.3 DeepSeek 系列模型

|版本|参数量|发布时间|特点|
|-|-|-|-|
|DeepSeek-V1|67B|2024年1月|专注于自然语言处理和编码任务，128K上下文窗口，多模态方面较弱|
|DeepSeek-V2|236B|2024年5月|性能比V1有显著提升，训练成本低，开源|
|DeepSeek-V2.5|236B|2024年9月|来自于 V2 的 Chat 和 Coder 两个版本的合并，提高通用能力|
|DeepSeek-V3|671B|2024年12月|专注于知识类任务和数学推理，生成速度大幅提升|
|DeepSeek-R1-Zero|671B|2025年1月|纯强化学习训练的推理模型，推理能力强但输出中英文混杂，可读性差|
|DeepSeek-R1|671B|2025年1月|性能对标 OpenAI o1 正式版|

从 DeepSeek-R1 通过蒸馏方法得到的模型包括多个不同参数规模的版本，如 DeepSeek-R1-Distill-Qwen-1.5B、DeepSeek-R1-Distill-Qwen-7B、DeepSeek-R1-Distill-Qwen-14B、DeepSeek-R1-Distill-Qwen-32B、DeepSeek-R1-Distill-Llama-8B 和 DeepSeek-R1-Distill-Llama-70B。这些蒸馏模型在多个基准测试中表现出色，例如 DeepSeek-R1-Distill-Qwen-32B 在 AIME 2024 测试中达到了 72.6% 的 Pass@1 成绩，超越了其他开源模型。


### 9.1.3 成本与价格的竞争

当性能相当的时候，就需要比较成本与价格了。DeepSeek-R1 模型具有 671B 参数量，同 OpenAI 一样，也是以 API 的形式提供服务的。表 9.1.4 是 DeepSeek-R1 与 OpenAI-o1 的成本与价格比较。

表 9.1.4 DeepSeek-R1 与 OpenAI-o1 的成本与价格比较

||DeepSeek-R1|OpenAI-o1|
|-|-|-|
|训练成本|约550万美元|约5亿美元|
|输入token|0.55美元/百万token|15美元/百万token|
|输出token|2.19美元/百万token|60美元/百万token|

可以看到，DeepSeek-R1 使用不算高端的 2000 块 H800 卡训练耗时不到 2 个月，训练成本只有 OpenAI-o1 的 1.2%，所以其提供的 API 价格也是后者的 1/27，这一点甚至令华尔街资本市场产生了动荡。当然，这种训练成本是纯文字意义上的，并没有计算该公司之前在大语言模型技术上的投入与积累。

### 9.1.4 技术竞争

竞争不只是体现在硬件的投入方面，各公司在算法、架构等软件方面也通过不断地推陈出新来提高自己的竞争力。Llama 和 DeepSeek 模型以及市面上的其它大模型都各自带来了一些亮眼的技术细节，比如：

- 旋转位置编码使得长上下文成为可能；

- 组相对策略优化改善了传统的近端策略优化的训练模式；

- 改进的混合专家模型带来更稀疏的模型结构和更好的预测效果；

- 强化学习算法为训练长思维链推理模型提供了可能性；

- 多头潜在注意力机制可以节省大量的 KV 缓存；

- 多 token 预测技术提高预测时的生成速度，并同时保证生成质量；

- 使用监督微调与强化学习算法交叉进行多阶段模型训练。

本章的后续内容将会对这些技术给与详细的讲解。
