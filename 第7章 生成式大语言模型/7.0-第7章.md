
# 第 7 章 生成式大语言模型

【本章要点】

OpenAI 的 GPT-3 模型的 1750 亿的参数规模在发布之初令人震惊，从此揭开了大语言模型的序幕，相信经过了前面六章的知识铺垫，学习本章及以后的内容会非常容易。在 GPT-3 中提出的小样本学习、元学习、上下文学习等概念是我们要讲解的重点，而 GPT-3.5 的知识点在于符合人类反馈的指令微调和对话生成。
